# DD2437NeuralNetwork

There are 4 lab sessions.

## Lab 1 : Learning and generalisation in feed-forward networks â€” from perceptron learning to backprop   

Main objectives :  
* to design and apply networks in classification, function approximation, and generalization tasks
* to identify key limitations of single-layer networks
* to configure and monitor the behavior of learning algorithms for single- and multi-layer perceptrons networks
* to recognize risks associated with backpropagation and minimize them for robust learning of multi-layer perceptrons.

## Lab 2 : Radial basis functions, competitive learning and self-organisation   

Main objectives :    
In this lab, we have used an RBF network to approximate one- and two-dimensional functions. And we have developed a competitive learning algorithm to automate the process of RBF unit initialization. Furthermore, We have implemented the core algorithm of SOM and used it for three different tasks.

## Lab 3 : Hopfield Networks   

Main objectives :   
* Understand the principles underlying the operation and functionality of auto-associative networks 
* Train the Hopfield network
* Study the attractor dynamics of Hopfield networks the concept of the energy function 
* Understand how auto-associative networks can do pattern completion and noise reduction 
* Investigate the question of storage capacity and explain features that help increase it in associative memories

## Lab 4 : Restricted Boltzmann Machines and Deep Belief Nets

Main objectives : 
* Understand the learning process of RBMs 
* Apply basic algorithms for unsupervised greedy pretraining of RBM layers and supervised greedy pretraining of DBN 
* Design multi-layer neural network architectures based on RBM layers for classification problems 
* Study the functionality of DBNs including generative aspects
